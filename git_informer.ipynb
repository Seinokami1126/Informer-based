{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8856dd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\17306\\miniconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:371: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  lr 0.312500 |  loss 0.15707| acc 1.000000\n",
      "| epoch   1 |  lr 0.312500 |  loss 0.12920| acc 1.000000\n",
      "| epoch   1 |  lr 0.312500 |  loss 0.18402| acc 0.987500\n",
      "| epoch   1 |  lr 0.312500 |  loss 0.12890| acc 1.000000\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  8.11s | test_acc: 0.996250 |  \n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 442>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    437\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mex30_85.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 443\u001b[0m     \u001b[43mtrain_informer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtrain_informer\u001b[1;34m()\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m89\u001b[39m)\n\u001b[0;32m    412\u001b[0m epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 413\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlost\u001b[49m\u001b[43m,\u001b[49m\u001b[43macr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlossfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_data, lost, acr, model, lossfix, lr, optimizer, scheduler, epochs, epoch)\u001b[0m\n\u001b[0;32m    354\u001b[0m data \u001b[38;5;241m=\u001b[39m input_trans(data,batch_size) \n\u001b[0;32m    355\u001b[0m data \u001b[38;5;241m=\u001b[39m noramlization(data)\n\u001b[1;32m--> 356\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    357\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mreshape([batch_size])\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m    358\u001b[0m loss \u001b[38;5;241m=\u001b[39m lossfix(output,targets)\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32mD:\\Users\\17306\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mTransAm.forward\u001b[1;34m(self, src)\u001b[0m\n\u001b[0;32m    335\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[0;32m    336\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_block(output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 337\u001b[0m output,attns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    338\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    339\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder2[\u001b[38;5;241m0\u001b[39m](output\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[1;32mD:\\Users\\17306\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, attn_mask)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attn_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_layers:\n\u001b[1;32m--> 277\u001b[0m         x, attn \u001b[38;5;241m=\u001b[39m \u001b[43mattn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m         attns\u001b[38;5;241m.\u001b[39mappend(attn)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Users\\17306\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[1;34m(self, x, attn_mask)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, attn_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# x [B, L, D]\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m# x = x + self.dropout(self.attention(\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m#     x, x, x,\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m#     attn_mask = attn_mask\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# ))\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m     new_x, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(new_x)\n\u001b[0;32m    252\u001b[0m     y \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n",
      "File \u001b[1;32mD:\\Users\\17306\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mAttentionLayer.forward\u001b[1;34m(self, queries, keys, values, attn_mask)\u001b[0m\n\u001b[0;32m    126\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_projection(keys)\u001b[38;5;241m.\u001b[39mview(B, S, H, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    127\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_projection(values)\u001b[38;5;241m.\u001b[39mview(B, S, H, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 129\u001b[0m out, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(B, L, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_projection(out), attn\n",
      "File \u001b[1;32mD:\\Users\\17306\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mProbAttention.forward\u001b[1;34m(self, queries, keys, values, attn_mask)\u001b[0m\n\u001b[0;32m    222\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_initial_context(values, L_Q)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# update the context with selected top_k queries\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m context, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores_top\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL_Q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mcontiguous(), attn\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mProbAttention._update_context\u001b[1;34m(self, context_in, V, scores, index, L_Q, attn_mask)\u001b[0m\n\u001b[0;32m    187\u001b[0m     scores\u001b[38;5;241m.\u001b[39mmasked_fill_(attn_mask\u001b[38;5;241m.\u001b[39mmask, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    189\u001b[0m attn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# nn.Softmax(dim=-1)(scores)\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m context_in[torch\u001b[38;5;241m.\u001b[39marange(B)[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[0;32m    192\u001b[0m            torch\u001b[38;5;241m.\u001b[39marange(H)[\u001b[38;5;28;01mNone\u001b[39;00m, :, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[0;32m    193\u001b[0m            index, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn, V)\u001b[38;5;241m.\u001b[39mtype_as(context_in)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_attention:\n\u001b[0;32m    195\u001b[0m     attns \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mones([B, H, L_V, L_V])\u001b[38;5;241m/\u001b[39mL_V)\u001b[38;5;241m.\u001b[39mtype_as(attn)\u001b[38;5;241m.\u001b[39mto(attn\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math as ms\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from d2l import torch as d2l\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from matplotlib.animation import FuncAnimation\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "# torch.manual_seed(0)\n",
    "# np.random.seed(0)\n",
    "\n",
    "# This concept is also called teacher forceing.\n",
    "# The flag decides if the loss will be calculted over all\n",
    "# or just the predicted values.\n",
    "calculate_loss_over_all_values = False\n",
    "cypl = 200\n",
    "batch_size = 80 # batch size\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"1.同时产生多D数据污染\n",
    "2.对D需要进行编码\n",
    "\"\"\"\n",
    "\n",
    "def get_data():\n",
    "#     训练集路径\n",
    "    data = pd.read_csv('E:/论文/数据/fx3/wz50_pos_noise_35.0000.csv', encoding='GBK', chunksize=100,header = None) \n",
    "    data = pd.concat(data, ignore_index=True)\n",
    "    data = data.loc[:, :]\n",
    "    train_data, test_data = train_test_split(data, train_size=0.8, random_state=np.random.randint(1,100))\n",
    "    train_data =torch.tensor(np.array(train_data)).float()\n",
    "    test_data =torch.tensor(np.array(test_data)).float()\n",
    "    return train_data, test_data\n",
    "\n",
    "def input_trans(data,batch_size):\n",
    "    data = data.reshape(cypl,batch_size)\n",
    "    data=data.cpu()\n",
    "    data = data.reshape(cypl,batch_size,1).to(device)\n",
    "    return data\n",
    "\n",
    "def noramlization(data):\n",
    "    return (data - torch.mean(data))/torch.std(data)\n",
    "\n",
    "def get_batch(source,i, batch_size):\n",
    "  #  seq_len = min(batch_size, len(source) - 1 - i)\n",
    "    if i + batch_size > len(source):  # 如果不够，直接返回None\n",
    "        return None, None\n",
    "    else:\n",
    "        seq_len = batch_size\n",
    "        data = source[i:i + seq_len]\n",
    "        target = data[:,-1]\n",
    "        data1 = data[:,0:cypl]\n",
    "        data1 = data1.t().to(device)\n",
    "        target = target.reshape(1,batch_size).to(device)\n",
    "        return data1,target\n",
    "    \n",
    "def time_embedding_pos(data,pos):\n",
    "    data = data.reshape(data.shape[0],data.shape[1])\n",
    "    data =data.t()\n",
    "    pos = pos.transpose(0,1)\n",
    "    sfr = data\n",
    "    box = torch.zeros(data.shape[0],data.shape[1],cypl)\n",
    "    box[:,:,0] = sfr\n",
    "    for j in range(len(box[0,:,0])):\n",
    "        box[:,j,1:j+1] = torch.flip(box[:,0:j,0], dims=[1])\n",
    "    box = box.to(device)\n",
    "    posi = pos[:,:,1:]\n",
    "    \n",
    "    box[:,:,1:] += posi\n",
    "    box = box.transpose(0,1).to(device)\n",
    "    return box\n",
    "\n",
    "def dis(src):\n",
    "    d = src.shape[0]\n",
    "    for i in range(d):\n",
    "        src[i,:,1:] = src[i,:,1:] * src[i,-1,0]\n",
    "    return src\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=cypl):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-ms.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        # pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "     \n",
    "        fd = x + self.pe[:x.size(0), :]\n",
    "        \n",
    "        return fd\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model//n_heads)\n",
    "        d_values = d_values or (d_model//n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "\n",
    "class ProbAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(ProbAttention, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n",
    "        # Q [B, H, L, D]\n",
    "        B, H, L_K, E = K.shape\n",
    "        _, _, L_Q, _ = Q.shape\n",
    "\n",
    "        # calculate the sampled Q_K\n",
    "        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
    "        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n",
    "        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n",
    "        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze()\n",
    "\n",
    "        # find the Top_k query with sparisty measurement\n",
    "        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
    "        M_top = M.topk(n_top, sorted=False)[1]\n",
    "\n",
    "        # use the reduced Q to calculate Q_K\n",
    "        Q_reduce = Q[torch.arange(B)[:, None, None],\n",
    "                     torch.arange(H)[None, :, None],\n",
    "                     M_top, :] # factor*ln\n",
    "        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n",
    "\n",
    "        return Q_K, M_top\n",
    "\n",
    "    def _get_initial_context(self, V, L_Q):\n",
    "        B, H, L_V, D = V.shape\n",
    "        if not self.mask_flag:\n",
    "            # V_sum = V.sum(dim=-2)\n",
    "            V_sum = V.mean(dim=-2)\n",
    "            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n",
    "        else: # use mask\n",
    "            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n",
    "            contex = V.cumsum(dim=-2)\n",
    "        return contex\n",
    "\n",
    "    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n",
    "        B, H, L_V, D = V.shape\n",
    "\n",
    "        if self.mask_flag:\n",
    "            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n",
    "\n",
    "        context_in[torch.arange(B)[:, None, None],\n",
    "                   torch.arange(H)[None, :, None],\n",
    "                   index, :] = torch.matmul(attn, V).type_as(context_in)\n",
    "        if self.output_attention:\n",
    "            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n",
    "            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n",
    "            return (context_in, attns)\n",
    "        else:\n",
    "            return (context_in, None)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask):\n",
    "        B, L_Q, H, D = queries.shape\n",
    "        _, L_K, _, _ = keys.shape\n",
    "\n",
    "        queries = queries.transpose(2,1)\n",
    "        keys = keys.transpose(2,1)\n",
    "        values = values.transpose(2,1)\n",
    "\n",
    "        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n",
    "        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n",
    "\n",
    "        U_part = U_part if U_part<L_K else L_K\n",
    "        u = u if u<L_Q else L_Q\n",
    "        \n",
    "        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n",
    "\n",
    "        # add scale factor\n",
    "        scale = self.scale or 1./np.sqrt(D)\n",
    "        if scale is not None:\n",
    "            scores_top = scores_top * scale\n",
    "        # get the context\n",
    "        context = self._get_initial_context(values, L_Q)\n",
    "        # update the context with selected top_k queries\n",
    "        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n",
    "        \n",
    "        return context.contiguous(), attn\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4*d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x [B, L, D]\n",
    "        # x = x + self.dropout(self.attention(\n",
    "        #     x, x, x,\n",
    "        #     attn_mask = attn_mask\n",
    "        # ))\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask = attn_mask\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1,1))\n",
    "\n",
    "        return self.norm2(x+y), attn\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "    \n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self,factor=1, dropout=0.1,attn='prob', d_model=12 ,n_heads = 1,output_attention=False,\n",
    "                 e_layers = 1,d_ff=12,activation='gelu',device=torch.device('cuda:0')):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(cypl)\n",
    "        self.lru = nn.LeakyReLU(negative_slope=0.01, inplace=False)\n",
    "        self.attn = attn\n",
    "        self.Relu=nn.ReLU()\n",
    "        self.maxpooling = torch.nn.MaxPool1d(6, stride=1, padding=1)\n",
    "        self.BN = nn.BatchNorm1d(300)\n",
    "        self.cov1 = nn.Conv1d(in_channels=cypl,out_channels=200,kernel_size=10,padding = 8)\n",
    "        self.cov2 = nn.Conv1d(in_channels=200,out_channels=100,kernel_size=3,padding = 2)\n",
    "        self.cov3 = nn.Conv1d(in_channels=100,out_channels=12,kernel_size=1,padding = 0)\n",
    "        self.cov_block = nn.Sequential(self.cov1,self.Relu,self.maxpooling,\n",
    "                                       self.cov2,self.Relu,self.maxpooling,\n",
    "                                       self.cov3,self.Relu,self.maxpooling)\n",
    "        if attn=='prob':\n",
    "            Attn = ProbAttention \n",
    "        self.encoder = Encoder(\n",
    "                [\n",
    "                    EncoderLayer(\n",
    "                        AttentionLayer(Attn(False, factor, attention_dropout = dropout, output_attention =output_attention), \n",
    "                                    d_model, n_heads),\n",
    "                        d_model,\n",
    "                        d_ff,\n",
    "                        dropout=dropout,\n",
    "                        activation=activation\n",
    "                    ) for l in range(e_layers)\n",
    "                ],\n",
    "            )\n",
    "          \n",
    "        self.decoder = nn.Sequential(nn.Linear(12, 5),nn.Linear(5, 1))\n",
    "        self.decoder2 = nn.Sequential(nn.Linear(cypl,120),nn.Tanh(),\n",
    "                                      nn.Linear(120,100),nn.Tanh(),\n",
    "                                      nn.Linear(100,10),nn.Tanh(),\n",
    "                                      nn.Linear(10,2),nn.Tanh()\n",
    "                                     )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.4\n",
    "        self.decoder[0].bias.data.zero_()\n",
    "        self.decoder[0].weight.data.uniform_(-initrange, initrange)\n",
    "        for i in range(0,len(self.decoder2),2):\n",
    "            self.decoder2[i].bias.data.zero_()\n",
    "            self.decoder2[i].weight.data.uniform_(-initrange, initrange)\n",
    "    def forward(self, src):\n",
    "        output = self.pos_encoder(src)\n",
    "        output = self.cov_block(output.transpose(0,2).transpose(0,1))\n",
    "        output,attns = self.encoder(output.transpose(0,2).transpose(1,2)) \n",
    "        output = self.decoder(output.transpose(0,1)).squeeze(2)\n",
    "        output = self.decoder2[0](output.float())\n",
    "        for i in range(1,len(self.decoder2)): \n",
    "            output = self.decoder2[i](output)\n",
    "            output = noramlization(output)\n",
    "        return output\n",
    "\n",
    "def train(train_data,lost,acr,model,lossfix,lr,optimizer,scheduler,epochs,epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n",
    "        \n",
    "        data, targets = get_batch(train_data, i, batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        data = input_trans(data,batch_size) \n",
    "        data = noramlization(data)\n",
    "        output = model(data).float()\n",
    "        targets = targets.reshape([batch_size]).long()\n",
    "        loss = lossfix(output,targets).sum()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        lost.append(float(loss))\n",
    "        acr.append(accuracy(output,targets))\n",
    "        log_interval = int(len(train_data) / batch_size / 4)\n",
    "        total_loss += loss.item()\n",
    "#             cur_loss = total_loss / log_interval\n",
    "        elapsed = time.time() - start_time\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            print('| epoch {:3d} |  '\n",
    "                  'lr {:02.6f} |  '\n",
    "\n",
    "                  'loss {:5.5f}| acc {:2f}'.format(\n",
    "                epoch,   scheduler.get_lr()[0],\n",
    "\n",
    "                loss,accuracy(output,targets)))  # , math.exp(cur_loss)\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "def accuracy(y_hat, y):\n",
    "    m = nn.Softmax(dim = 1)\n",
    "    y_hat = m(y_hat)\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return round(float(cmp.type(y.dtype).sum())/len(y.t()),6)\n",
    "\n",
    "def train_informer():\n",
    "    lossfix=nn.CrossEntropyLoss()\n",
    "    lossfix = lossfix.to(device)\n",
    "    model = TransAm().to(device)\n",
    "    lr = 1*batch_size/256\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, gamma=0.75)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs = 100 # The number of epochs\n",
    "    best_model = None\n",
    "    lost = []\n",
    "    acr = []\n",
    "    ts_lost = []\n",
    "    train_data, test_data = get_data()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "\n",
    "        train_data=train_data[torch.randperm(train_data.size(0))]\n",
    "\n",
    "\n",
    "        print('-' * 89)\n",
    "\n",
    "        print('-' * 89)\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "        train(train_data,lost,acr,model,lossfix,lr,optimizer,scheduler,epochs,epoch)\n",
    "\n",
    "        test_acc = 0\n",
    "\n",
    "        for i in range(20):\n",
    "\n",
    "            tst,tar = get_batch(test_data,np.random.randint(1,len(test_data) - batch_size - 1),batch_size)\n",
    "\n",
    "            tst = input_trans(tst,batch_size)\n",
    "            tst = noramlization(tst)\n",
    "            tst_output = model(tst).float()\n",
    "            test_acc += accuracy(tst_output,tar)\n",
    "        ts_lost.append(test_acc/20) \n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | test_acc: {:5.6f} |  '.format(\n",
    "            epoch, (time.time() - epoch_start_time),test_acc/20\n",
    "           ))  # , math.exp(val_loss) | valid ppl {:8.2f}\n",
    "        print('-' * 89)\n",
    "\n",
    "        if test_acc/20 >=0.99 :\n",
    "            torch.save(model, 'IN_99.pt')\n",
    "        if test_acc/20 >= 0.95 and test_acc/20<0.99:\n",
    "            torch.save(model, 'IN_95.pt')\n",
    "        if test_acc/20 >=0.85 and test_acc/20<0.95:\n",
    "            torch.save(model, 'IN_85.pt')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    train_informer()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
